{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4JDkii2rxOg"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xowLivSD6bro",
    "outputId": "80c2fc1c-5af6-4c0f-93ac-50a63dc08a75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pathlib\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.utils import shuffle\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.losses import categorical_crossentropy\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from tensorflow.keras import regularizers\r\n",
    "from tensorflow.keras import backend as K\r\n",
    "\r\n",
    "from util import *\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUFCiglo5II9",
    "outputId": "5619a59b-f2e1-4987-9b03-1dc55844e141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  1.14.0\n",
      "Eager mode:  False\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "# tf.compat.v1.enable_eager_execution() # Enable eager execution\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "# print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = pathlib.Path.cwd()\n",
    "\n",
    "# feature_path = HOME_DIR / 'data' / 'processed'/ 'IEMOCAP' / 'extracted_feature.pk'\n",
    "feature_path = 'D:/extracted_features.pk'\n",
    "\n",
    "label_path = HOME_DIR / 'data' / 'processed' / 'IEMOCAP' / 'FC_label.txt'\n",
    "processed_id_path = HOME_DIR / 'data' / 'processed' / 'IEMOCAP' / 'processed_ids.txt'\n",
    "dataset_path = HOME_DIR / 'data' / 'raw'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAo1dHV8-WVX"
   },
   "source": [
    "## Training plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lakbh-NzFdyr"
   },
   "outputs": [],
   "source": [
    "def acc_plot(history, fold, save_path):\n",
    "    '''\n",
    "    Plot training accuracy graph.\n",
    "    '''\n",
    "\n",
    "    epochs = range(len(history.history['acc']))\n",
    "\n",
    "    plt.plot(epochs, history.history['acc'], 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, history.history['val_acc'], 'b', label='Validation accuracy')\n",
    "    plt.title(f'Training and validation accuracy (Text) - Fold#{fold}')\n",
    "    plt.legend(loc=0)\n",
    "    plt.figure()\n",
    "\n",
    "    plt.savefig(save_path + f'/acc_fold_#{fold}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NJHDLi6ha6dI"
   },
   "outputs": [],
   "source": [
    "def loss_plot(history, fold, save_path):\n",
    "    '''\n",
    "    Plot training loss graph.\n",
    "    '''\n",
    "\n",
    "    epochs = range(len(history.history['loss']))\n",
    "\n",
    "    plt.plot(epochs, history.history['loss'], 'r', label='Training loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], 'b', label='Validation loss')\n",
    "    plt.title(f'Training and validation loss (Text) - Fold#{fold}')\n",
    "    plt.legend(loc=0)\n",
    "    plt.figure()\n",
    "\n",
    "    plt.savefig(save_path + f'/loss_fold_#{fold}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "h_unWA_U9VzA"
   },
   "outputs": [],
   "source": [
    "def shuffle_dataset(features, labels):\r\n",
    "    '''\r\n",
    "    Shuffle features and labels in unison.\r\n",
    "    '''\r\n",
    "    shuffler = np.random.permutation(labels.index)\r\n",
    "\r\n",
    "    features_shuffled, labels_shuffled = features[shuffler], labels(shuffler)\r\n",
    "\r\n",
    "    return features_shuffled, labels_shuffled\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, Y, batch_size):\r\n",
    "    '''\r\n",
    "    Data generator.\r\n",
    "    '''\r\n",
    "    # batch = []\r\n",
    "\r\n",
    "    # while True:\r\n",
    "    #     for i in ids:\r\n",
    "    #         batch.append(i)\r\n",
    "    #         if len(batch) == batch_size:\r\n",
    "    #             yield X[batch], Y[batch]\r\n",
    "    #             batch = []\r\n",
    "\r\n",
    "    idx = 0\r\n",
    "    while True:\r\n",
    "        if idx + batch_size > len(X):\r\n",
    "            idx = 0\r\n",
    "            break\r\n",
    "\r\n",
    "        start = idx\r\n",
    "        idx += batch_size\r\n",
    "\r\n",
    "        yield X[start:start+batch_size], Y[start:start+batch_size]\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extracted feature data\r\n",
    "X = np.load('D:/processed_features.npz', mmap_mode='r')\r\n",
    "# X = X['arr_0']\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x1fbe3ca3c08>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Trc3U4g1J5BX",
    "outputId": "04d94588-7e30-46df-e9c3-152c80ffaed7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['ang', 'hap', 'neu', 'sad'], dtype=object)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1O6VJWRJE1m"
   },
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\r\n",
    "Y = encoder.fit_transform(label[['label']])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PS4DIeNjpp8B"
   },
   "outputs": [],
   "source": [
    "X, Y = shuffle_dataset(X, Y)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPTKOvBQq34v",
    "outputId": "28253982-2580-4319-873b-15b831d85659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train length --> 5000, Y-Train length --> 5000\n",
      "X-Test length --> 531, Y-Test length --> 531\n"
     ]
    }
   ],
   "source": [
    "# x_train, y_train = X[:5000], Y[:5000]\r\n",
    "# # x_test, y_test = X[5000:], Y[5000:]\r\n",
    "\r\n",
    "# print(f'X-Train length --> {len(x_train)}, Y-Train length --> {len(y_train)}')\r\n",
    "\r\n",
    "# data_dict = {'features':feature_train, 'label':label_train}\r\n",
    "# dataset = pd.DataFrame.from_dict(data_dict)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjUhjkmGJA-Z"
   },
   "source": [
    "## One-hot encode label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhErmRr5FkmK"
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3b0ztVxgFmZ3"
   },
   "outputs": [],
   "source": [
    "# K-fold configuration\n",
    "num_folds = 5\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32 #64\n",
    "loss_function = categorical_crossentropy\n",
    "no_classes = 4\n",
    "no_epochs = 30\n",
    "grad_clip_value = 5.0\n",
    "learn_rate = 1e-4\n",
    "verbosity = 1\n",
    "optimizer = Adam(learning_rate=learn_rate, clipnorm=grad_clip_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StOXP6klC81Q"
   },
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "fold = 1\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = batch_generator(X, Y, batch_size)\r\n",
    "validation_generator = batch_generator(X, Y, batch_size)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u-CoYqDByq6A",
    "outputId": "d8313c55-6333-45da-9f25-0c36f252dd35"
   },
   "outputs": [],
   "source": [
    "# Train model\r\n",
    "\r\n",
    "model = tf.keras.Sequential([\r\n",
    "                            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, \r\n",
    "                                                                                return_sequences=True,\r\n",
    "                                                                                activation= 'relu',\r\n",
    "                                                                                dropout=0.4, \r\n",
    "                                                                                kernel_regularizer=regularizers.l2(1e-5)),\r\n",
    "                                                            ),\r\n",
    "                            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, \r\n",
    "                                                                                activation= 'relu', \r\n",
    "                                                                                dropout=0.5, \r\n",
    "                                                                                kernel_regularizer=regularizers.l2(1e-5))),\r\n",
    "                            tf.keras.layers.Dense(no_classes, activation='softmax')\r\n",
    "])\r\n",
    "\r\n",
    "model.compile(loss=loss_function,\r\n",
    "                optimizer=optimizer,\r\n",
    "                metrics=['accuracy'])\r\n",
    "\r\n",
    "\r\n",
    "# Provide training information\r\n",
    "print('------------------------------------------------------------------------')\r\n",
    "print(f'Training for fold #{fold} ...')\r\n",
    "\r\n",
    "history = model.fit(generator, \r\n",
    "                    epochs=no_epochs,\r\n",
    "                    batch_size=batch_size,\r\n",
    "                    verbose=verbosity,\r\n",
    "                    validation_data=(validation_generator),\r\n",
    "                    use_multiprocessing=True)\r\n",
    "\r\n",
    "\r\n",
    "acc_plot(history, fold, save_path='/content/drive/MyDrive/Colab Notebooks/My Project - SER/fold_result_plot/text')\r\n",
    "loss_plot(history, fold, save_path='/content/drive/MyDrive/Colab Notebooks/My Project - SER/fold_result_plot/text')\r\n",
    "\r\n",
    "# loss, acc = model.evaluate(X_val, y_val, verbose=0)\r\n",
    "\r\n",
    "print(f'Saving Model for fold #{fold}...')\r\n",
    "model.save(f'/content/drive/MyDrive/Colab Notebooks/My Project - SER/text_fold_models/fold_{fold}_model.h5')\r\n",
    "\r\n",
    "K.clear_session()\r\n",
    "\r\n",
    "print(f'Score for fold #{fold}: {model.metrics_names[0]} of {loss}; {model.metrics_names[1]} of {acc * 100}%')\r\n",
    "acc_per_fold.append(acc * 100)\r\n",
    "loss_per_fold.append(loss)\r\n",
    "\r\n",
    "fold += 1 # Increase fold number\r\n",
    "\r\n",
    "session.close()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "REvJ5bQcp0cQ",
    "outputId": "b7d8751d-a32c-48f2-e779-ab55bc7d4e00"
   },
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for index, acc in enumerate(acc_per_fold):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {index+1} - Loss: {loss_per_fold[index]} - Accuracy: {acc_per_fold[index]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8c8taWCs6Pgi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "speech_train.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c5e48f84046969b800ff52f6d80523bcd1ca3fb1a99f1449e4197bf6c73dc096"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}