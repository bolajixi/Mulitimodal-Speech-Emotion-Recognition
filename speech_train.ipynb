{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4JDkii2rxOg"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xowLivSD6bro",
    "outputId": "80c2fc1c-5af6-4c0f-93ac-50a63dc08a75"
   },
   "outputs": [],
   "source": [
    "import pathlib\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.utils import shuffle\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.losses import categorical_crossentropy\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from tensorflow.keras import regularizers\r\n",
    "from tensorflow.keras import backend as K\r\n",
    "\r\n",
    "from util import *\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUFCiglo5II9",
    "outputId": "5619a59b-f2e1-4987-9b03-1dc55844e141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  1.14.0\n",
      "Eager mode:  False\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "# tf.compat.v1.enable_eager_execution() # Enable eager execution\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "# print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = pathlib.Path.cwd()\n",
    "\n",
    "# feature_path = HOME_DIR / 'data' / 'processed'/ 'IEMOCAP' / 'extracted_feature.pk'\n",
    "feature_path = 'D:/extracted_features.pk'\n",
    "\n",
    "label_path = HOME_DIR / 'data' / 'processed' / 'IEMOCAP' / 'FC_label.txt'\n",
    "processed_id_path = HOME_DIR / 'data' / 'processed' / 'IEMOCAP' / 'processed_ids.txt'\n",
    "dataset_path = HOME_DIR / 'data' / 'raw'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAo1dHV8-WVX"
   },
   "source": [
    "## Training plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lakbh-NzFdyr"
   },
   "outputs": [],
   "source": [
    "def acc_plot(history, fold, save_path):\n",
    "    '''\n",
    "    Plot training accuracy graph.\n",
    "    '''\n",
    "\n",
    "    epochs = range(len(history.history['acc']))\n",
    "\n",
    "    plt.plot(epochs, history.history['acc'], 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, history.history['val_acc'], 'b', label='Validation accuracy')\n",
    "    plt.title(f'Training and validation accuracy (Text) - Fold#{fold}')\n",
    "    plt.legend(loc=0)\n",
    "    plt.figure()\n",
    "\n",
    "    plt.savefig(save_path + f'/acc_fold_#{fold}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NJHDLi6ha6dI"
   },
   "outputs": [],
   "source": [
    "def loss_plot(history, fold, save_path):\n",
    "    '''\n",
    "    Plot training loss graph.\n",
    "    '''\n",
    "\n",
    "    epochs = range(len(history.history['loss']))\n",
    "\n",
    "    plt.plot(epochs, history.history['loss'], 'r', label='Training loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], 'b', label='Validation loss')\n",
    "    plt.title(f'Training and validation loss (Text) - Fold#{fold}')\n",
    "    plt.legend(loc=0)\n",
    "    plt.figure()\n",
    "\n",
    "    plt.savefig(save_path + f'/loss_fold_#{fold}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, Y, batch_size):\r\n",
    "    '''\r\n",
    "    Data generator.\r\n",
    "    '''\r\n",
    "    # batch = []\r\n",
    "\r\n",
    "    # while True:\r\n",
    "    #     for i in ids:\r\n",
    "    #         batch.append(i)\r\n",
    "    #         if len(batch) == batch_size:\r\n",
    "    #             yield X[batch], Y[batch]\r\n",
    "    #             batch = []\r\n",
    "\r\n",
    "    idx = 0\r\n",
    "    while True:\r\n",
    "        if idx + batch_size > len(X):\r\n",
    "            idx = 0\r\n",
    "            break\r\n",
    "\r\n",
    "        start = idx\r\n",
    "        idx += batch_size\r\n",
    "\r\n",
    "        yield X[start:start+batch_size], Y[start:start+batch_size]\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extracted feature data\r\n",
    "X = np.load('D:/processed_features.npz', mmap_mode='r')\r\n",
    "# X = X['arr_0']\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x1fbe3ca3c08>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPTKOvBQq34v",
    "outputId": "28253982-2580-4319-873b-15b831d85659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train length --> 5000, Y-Train length --> 5000\n",
      "X-Test length --> 531, Y-Test length --> 531\n"
     ]
    }
   ],
   "source": [
    "# x_train, y_train = X[:5000], Y[:5000]\r\n",
    "# # x_test, y_test = X[5000:], Y[5000:]\r\n",
    "\r\n",
    "# print(f'X-Train length --> {len(x_train)}, Y-Train length --> {len(y_train)}')\r\n",
    "\r\n",
    "# data_dict = {'features':feature_train, 'label':label_train}\r\n",
    "# dataset = pd.DataFrame.from_dict(data_dict)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjUhjkmGJA-Z"
   },
   "source": [
    "## One-hot encode label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhErmRr5FkmK"
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3b0ztVxgFmZ3"
   },
   "outputs": [],
   "source": [
    "# K-fold configuration\r\n",
    "num_folds = 5\r\n",
    "\r\n",
    "# Model configuration\r\n",
    "batch_size = 32 #64\r\n",
    "loss_function = categorical_crossentropy\r\n",
    "no_classes = 4\r\n",
    "no_epochs = 30\r\n",
    "grad_clip_value = 5.0\r\n",
    "initial_learn_rate = 1e-4\r\n",
    "verbosity = 1\r\n",
    "\r\n",
    "# Learning rate decay\r\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\r\n",
    "    initial_learn_rate,\r\n",
    "    decay_steps=100000,\r\n",
    "    decay_rate=0.99, #0.96,\r\n",
    "    staircase=True)\r\n",
    "\r\n",
    "optimizer = Adam(learning_rate=lr_schedule, clipnorm=grad_clip_value)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StOXP6klC81Q"
   },
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "fold = 1\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = batch_generator(X, Y, batch_size)\r\n",
    "validation_generator = batch_generator(X, Y, batch_size)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u-CoYqDByq6A",
    "outputId": "d8313c55-6333-45da-9f25-0c36f252dd35"
   },
   "outputs": [],
   "source": [
    "# Train model\r\n",
    "\r\n",
    "model = tf.keras.Sequential([\r\n",
    "                            tf.keras.layers.Conv2d(\r\n",
    "                                128, (5, 3), activation='relu'),\r\n",
    "                            tf.keras.layers.MaxPool2D((2, 2)),\r\n",
    "                            tf.keras.layers.Conv2d(\r\n",
    "                                256, (5, 3), activation='relu'),\r\n",
    "                            tf.keras.layers.Conv2d(\r\n",
    "                                256, (5, 3), activation='relu'),\r\n",
    "                            tf.keras.layers.Flatten(),\r\n",
    "                            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,\r\n",
    "                                                                                activation= 'relu',\r\n",
    "                                                                                dropout=0.4, \r\n",
    "                                                                                kernel_regularizer=regularizers.l2(1e-5)),\r\n",
    "                                                            ),\r\n",
    "                            tf.keras.layers.Dense(\r\n",
    "                                64, activation='relu'),\r\n",
    "                            tf.keras.layers.Dense(no_classes, activation='softmax')\r\n",
    "])\r\n",
    "\r\n",
    "model.compile(loss=loss_function,\r\n",
    "                optimizer=optimizer,\r\n",
    "                metrics=['accuracy'])\r\n",
    "\r\n",
    "\r\n",
    "# Provide training information\r\n",
    "print('------------------------------------------------------------------------')\r\n",
    "print(f'Training for fold #{fold} ...')\r\n",
    "\r\n",
    "history = model.fit(generator, \r\n",
    "                    epochs=no_epochs,\r\n",
    "                    batch_size=batch_size,\r\n",
    "                    verbose=verbosity,\r\n",
    "                    validation_data=(validation_generator),\r\n",
    "                    use_multiprocessing=True)\r\n",
    "\r\n",
    "\r\n",
    "acc_plot(history, fold, save_path='/content/drive/MyDrive/Colab Notebooks/My Project - SER/fold_result_plot/text')\r\n",
    "loss_plot(history, fold, save_path='/content/drive/MyDrive/Colab Notebooks/My Project - SER/fold_result_plot/text')\r\n",
    "\r\n",
    "# loss, acc = model.evaluate(X_val, y_val, verbose=0)\r\n",
    "\r\n",
    "print(f'Saving Model for fold #{fold}...')\r\n",
    "model.save(f'/content/drive/MyDrive/Colab Notebooks/My Project - SER/text_fold_models/fold_{fold}_model.h5')\r\n",
    "\r\n",
    "K.clear_session()\r\n",
    "\r\n",
    "print(f'Score for fold #{fold}: {model.metrics_names[0]} of {loss}; {model.metrics_names[1]} of {acc * 100}%')\r\n",
    "acc_per_fold.append(acc * 100)\r\n",
    "loss_per_fold.append(loss)\r\n",
    "\r\n",
    "fold += 1 # Increase fold number\r\n",
    "\r\n",
    "session.close()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "REvJ5bQcp0cQ",
    "outputId": "b7d8751d-a32c-48f2-e779-ab55bc7d4e00"
   },
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for index, acc in enumerate(acc_per_fold):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {index+1} - Loss: {loss_per_fold[index]} - Accuracy: {acc_per_fold[index]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8c8taWCs6Pgi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "speech_train.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c5e48f84046969b800ff52f6d80523bcd1ca3fb1a99f1449e4197bf6c73dc096"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}