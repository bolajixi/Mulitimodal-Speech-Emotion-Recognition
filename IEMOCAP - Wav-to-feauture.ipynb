{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Audio Feautures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "import wave\n",
    "import python_speech_features as ps\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from util import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import python_speech_features as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUFCiglo5II9",
    "outputId": "5619a59b-f2e1-4987-9b03-1dc55844e141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  1.14.0\n",
      "Eager mode:  False\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "# tf.compat.v1.enable_eager_execution() # Enable eager execution\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "# print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = pathlib.Path.cwd()\n",
    "\n",
    "# feature_path = HOME_DIR / 'data' / 'processed'/ 'IEMOCAP' / 'extracted_feature.pk'\n",
    "feature_path = 'D:/extracted_features.pk'\n",
    "\n",
    "label_path = HOME_DIR / 'data' / 'processed' / 'IEMOCAP' / 'FC_label_test.txt'\n",
    "processed_id_path = HOME_DIR / 'data' / 'processed' / 'IEMOCAP' / 'processed_ids_test.txt'\n",
    "dataset_path = HOME_DIR / 'data' / 'raw'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    file = wave.open(filename, 'r')\n",
    "    params = file.getparams()\n",
    "    nchannels, sampwidth, framerate, wav_length = params[:4]\n",
    "    str_data = file.readframes(wav_length)\n",
    "    wavedata = np.fromstring(str_data, dtype=np.short)\n",
    "    time = np.arange(0, wav_length) * (1.0/framerate)\n",
    "    file.close()\n",
    "    return wavedata, time, framerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataset(features, labels):\n",
    "    # random.seed(24)\n",
    "\n",
    "    shuffler = np.random.permutation(len(features))\n",
    "    return features[shuffler], labels[shuffler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session1, # Num of files: 1819\n",
      "Session2, # Num of files: 3630\n",
      "Session3, # Num of files: 5766\n",
      "Session4, # Num of files: 7869\n"
     ]
    }
   ],
   "source": [
    "list_files = []\n",
    "\n",
    "for x in range(1, 5):\n",
    "    sess_title = 'Session' + str(x)\n",
    "\n",
    "    path = f'./data/raw/IEMOCAP_full_release/{sess_title}/sentences/wav'\n",
    "\n",
    "    file_search(str(path), list_files)\n",
    "    list_files = sorted(list_files)\n",
    "\n",
    "    print(f\"{sess_title}, # Num of files: {len(list_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of filenames in category, (Angry, Happy, Sad, Neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ids = []\n",
    "with open(str(processed_id_path)) as f:\n",
    "    full_ids = f.readlines()\n",
    "full_ids = [x.strip() for x in full_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = []\n",
    "\n",
    "for file_ in full_ids:\n",
    "    for file2 in list_files:\n",
    "        if file_+'.wav' == file2.split('\\\\')[-1]:\n",
    "            full_path.append(file2)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('./zscore40.pkl', 'rb') as f:\n",
    "        mean1, std1, mean2, std2, mean3, std3 = pickle.load(f)\n",
    "    return mean1, std1, mean2, std2, mean3, std3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1, std1, mean2, std2, mean3, std3 = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_size = 3548 #3548 - consider zero-indexing\n",
    "dataset_size = 942  # consider session 5 only(test set)\n",
    "filter_num = 40\n",
    "eps = 1e-5\n",
    "\n",
    "dataset = np.zeros((dataset_size, 300, filter_num, 3), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dataset_size = 0\n",
    "for filename in full_path:\n",
    "\n",
    "    data, time, rate = read_file(filename)\n",
    "    mel_spec = ps.logfbank(data, rate, nfilt=40)\n",
    "    delta1 = ps.delta(mel_spec, 2)\n",
    "    delta2 = ps.delta(delta1, 2)\n",
    "\n",
    "    time = mel_spec.shape[0]\n",
    "\n",
    "    if(time <= 300):\n",
    "        part = mel_spec\n",
    "        delta11 = delta1\n",
    "        delta21 = delta2\n",
    "\n",
    "        part = np.pad(\n",
    "            part, ((0, 300 - part.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "        delta11 = np.pad(\n",
    "            delta11, ((0, 300 - delta11.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "        delta21 = np.pad(\n",
    "            delta21, ((0, 300 - delta21.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "\n",
    "        dataset[dataset_size, :, :, 0] = (part - mean1)/(std1+eps)\n",
    "        dataset[dataset_size, :, :, 1] = (delta11 - mean2)/(std2+eps)\n",
    "        dataset[dataset_size, :, :, 2] = (delta21 - mean3)/(std3+eps)\n",
    "\n",
    "        dataset_size += 1\n",
    "\n",
    "    else:\n",
    "        for i in range(1):\n",
    "            if(i == 0):\n",
    "                begin = 0\n",
    "                end = begin + 300\n",
    "            else:\n",
    "                begin = time - 300\n",
    "                end = time\n",
    "\n",
    "            part = mel_spec[begin:end, :]\n",
    "            delta11 = delta1[begin:end, :]\n",
    "            delta21 = delta2[begin:end, :]\n",
    "\n",
    "            dataset[dataset_size, :, :, 0] = (part - mean1)/(std1+eps)\n",
    "            dataset[dataset_size, :, :, 1] = (delta11 - mean2)/(std2+eps)\n",
    "            dataset[dataset_size, :, :, 2] = (delta21 - mean3)/(std3+eps)\n",
    "\n",
    "            dataset_size += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jA4eEP5wu6nj"
   },
   "source": [
    "## Load and prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WwvIqtsJuJVq"
   },
   "outputs": [],
   "source": [
    "# Load label data\n",
    "label = []\n",
    "\n",
    "with open(str(label_path)) as f2:\n",
    "    category = f2.readlines()\n",
    "\n",
    "label = [y.strip() for y in category]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label Dataframe\n",
    "data_dict = {'label': label}\n",
    "label_dataset = pd.DataFrame.from_dict(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "label_encoded = encoder.fit_transform(label_dataset[['label']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, label = shuffle_dataset(dataset, label_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pre-processed data\n",
    "np.save('D:/processed_features3', features)\n",
    "np.save('D:/label3', label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold out test-set\n",
    "np.save(str(dataset_path) + '/X_test_set55', dataset)\n",
    "np.save(str(dataset_path) + '/Y_test_set55', label_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5e48f84046969b800ff52f6d80523bcd1ca3fb1a99f1449e4197bf6c73dc096"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
