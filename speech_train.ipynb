{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4JDkii2rxOg"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xowLivSD6bro",
    "outputId": "80c2fc1c-5af6-4c0f-93ac-50a63dc08a75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pathlib\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.utils import shuffle\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "from tensorflow.keras.losses import categorical_crossentropy\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from tensorflow.keras import regularizers\r\n",
    "\r\n",
    "from util import *\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUFCiglo5II9",
    "outputId": "5619a59b-f2e1-4987-9b03-1dc55844e141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  1.14.0\n",
      "Eager mode:  False\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "# tf.compat.v1.enable_eager_execution() # Enable eager execution\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "# print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = pathlib.Path.cwd()\r\n",
    "\r\n",
    "# feature_path = HOME_DIR / 'data' / 'processed'/ 'IEMOCAP' / 'extracted_feature.pk'\r\n",
    "feature_path = 'D:/extracted_features.pk'\r\n",
    "\r\n",
    "label_path = HOME_DIR / 'data' / 'processed' / 'IEMOCAP' / 'FC_label.txt'\r\n",
    "processed_id_path = HOME_DIR / 'data' / 'processed' / 'IEMOCAP' / 'processed_ids.txt'\r\n",
    "dataset_path = HOME_DIR / 'data' / 'raw'\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAo1dHV8-WVX"
   },
   "source": [
    "## Training plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lakbh-NzFdyr"
   },
   "outputs": [],
   "source": [
    "def acc_plot(history, fold, save_path):\n",
    "    '''\n",
    "    Plot training accuracy graph.\n",
    "    '''\n",
    "\n",
    "    epochs = range(len(history.history['acc']))\n",
    "\n",
    "    plt.plot(epochs, history.history['acc'], 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, history.history['val_acc'], 'b', label='Validation accuracy')\n",
    "    plt.title(f'Training and validation accuracy (Text) - Fold#{fold}')\n",
    "    plt.legend(loc=0)\n",
    "    plt.figure()\n",
    "\n",
    "    plt.savefig(save_path + f'/acc_fold_#{fold}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NJHDLi6ha6dI"
   },
   "outputs": [],
   "source": [
    "def loss_plot(history, fold, save_path):\n",
    "    '''\n",
    "    Plot training loss graph.\n",
    "    '''\n",
    "\n",
    "    epochs = range(len(history.history['loss']))\n",
    "\n",
    "    plt.plot(epochs, history.history['loss'], 'r', label='Training loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], 'b', label='Validation loss')\n",
    "    plt.title(f'Training and validation loss (Text) - Fold#{fold}')\n",
    "    plt.legend(loc=0)\n",
    "    plt.figure()\n",
    "\n",
    "    plt.savefig(save_path + f'/loss_fold_#{fold}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "h_unWA_U9VzA"
   },
   "outputs": [],
   "source": [
    "def shuffle_dataset(features, labels):\r\n",
    "    '''\r\n",
    "    Shuffle features and labels in unison.\r\n",
    "    '''\r\n",
    "    shuffler = np.random.permutation(labels.index)\r\n",
    "\r\n",
    "    features_shuffled, labels_shuffled = features[shuffler], labels.reindex(shuffler)\r\n",
    "\r\n",
    "    return features_shuffled, labels_shuffled\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extracted feature data\r\n",
    "features = np.load('D:/processed_features.npz')\r\n",
    "features = features['arr_0']\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "WwvIqtsJuJVq"
   },
   "outputs": [],
   "source": [
    "# Load label dataframe\r\n",
    "label = pd.read_pickle('D:/label_dataset.pkl')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "PS4DIeNjpp8B"
   },
   "outputs": [],
   "source": [
    "features, label = shuffle_dataset(features, label)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape --> (5531, 3409, 65),\t Label shape --> (5531, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'Features shape --> {features.shape},\\t Label shape --> {label.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPTKOvBQq34v",
    "outputId": "28253982-2580-4319-873b-15b831d85659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-Train length --> 5000, Y-Train length --> 5000\n",
      "X-Test length --> 531, Y-Test length --> 531\n"
     ]
    }
   ],
   "source": [
    "feature_train = features[:5000]\r\n",
    "label_train = label[:5000]\r\n",
    "\r\n",
    "feature_test = features[5000:]\r\n",
    "label_test = label[5000:]\r\n",
    "\r\n",
    "print(f'X-Train length --> {len(feature_train)}, Y-Train length --> {len(label_train)}')\r\n",
    "print(f'X-Test length --> {len(feature_test)}, Y-Test length --> {len(label_test)}')\r\n",
    "\r\n",
    "# data_dict = {'features':feature_train, 'label':label_train}\r\n",
    "# dataset = pd.DataFrame.from_dict(data_dict)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjUhjkmGJA-Z"
   },
   "source": [
    "## One-hot encode label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "-1O6VJWRJE1m"
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\r\n",
    "label_encode = enc.fit_transform(label_train[['label']])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Trc3U4g1J5BX",
    "outputId": "04d94588-7e30-46df-e9c3-152c80ffaed7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['ang', 'hap', 'neu', 'sad'], dtype=object)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhErmRr5FkmK"
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "3b0ztVxgFmZ3"
   },
   "outputs": [],
   "source": [
    "# K-fold configuration\n",
    "num_folds = 10\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 64\n",
    "loss_function = categorical_crossentropy\n",
    "no_classes = 4\n",
    "no_epochs = 30\n",
    "grad_clip_value = 5.0\n",
    "learn_rate = 1e-4\n",
    "verbosity = 1\n",
    "optimizer = Adam(learning_rate=learn_rate, clipnorm=grad_clip_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "StOXP6klC81Q"
   },
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\r\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\r\n",
    "fold = 1\r\n",
    "\r\n",
    "acc_per_fold = []\r\n",
    "loss_per_fold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u-CoYqDByq6A",
    "outputId": "d8313c55-6333-45da-9f25-0c36f252dd35"
   },
   "outputs": [],
   "source": [
    "# Train model\r\n",
    "for train_index, val_index in kfold.split(label_encode):\r\n",
    "\r\n",
    "    X_train = feature_train[train_index]\r\n",
    "    X_val = feature_train[val_index]\r\n",
    "\r\n",
    "    y_train = label_encode[train_index]\r\n",
    "    y_val = label_encode[val_index]\r\n",
    "\r\n",
    "\r\n",
    "    model = tf.keras.Sequential([\r\n",
    "                                tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, \r\n",
    "                                                                                   return_sequences=True,\r\n",
    "                                                                                   activation= 'relu',\r\n",
    "                                                                                   dropout=0.4, \r\n",
    "                                                                                   kernel_regularizer=regularizers.l2(1e-5)),\r\n",
    "                                                              input_shape=(5531, 3409, 65)),\r\n",
    "                                tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, \r\n",
    "                                                                                   activation= 'relu', \r\n",
    "                                                                                   dropout=0.5, \r\n",
    "                                                                                   kernel_regularizer=regularizers.l2(1e-5))),\r\n",
    "                                # tf.keras.layers.Average(),\r\n",
    "                                tf.keras.layers.Dense(128, activation='relu'),\r\n",
    "                                tf.keras.layers.Dense(no_classes, activation='softmax')\r\n",
    "    ])\r\n",
    "\r\n",
    "    model.compile(loss=loss_function,\r\n",
    "                  optimizer=optimizer,\r\n",
    "                  metrics=['accuracy'])\r\n",
    "    \r\n",
    "    # Provide training information\r\n",
    "    print('------------------------------------------------------------------------')\r\n",
    "    print(f'Training for fold #{fold} ...')\r\n",
    "\r\n",
    "    history = model.fit(X_train,\r\n",
    "                        y_train,\r\n",
    "                        epochs=no_epochs,\r\n",
    "                        batch_size=batch_size,\r\n",
    "                        verbose=verbosity,\r\n",
    "                        validation_data=(X_val, y_val))\r\n",
    "    \r\n",
    "    acc_plot(history, fold, save_path='/content/drive/MyDrive/Colab Notebooks/My Project - SER/fold_result_plot/text')\r\n",
    "    loss_plot(history, fold, save_path='/content/drive/MyDrive/Colab Notebooks/My Project - SER/fold_result_plot/text')\r\n",
    "    \r\n",
    "    loss, acc = model.evaluate(X_val, y_val, verbose=0)\r\n",
    "\r\n",
    "    print(f'Saving Model for fold #{fold}...')\r\n",
    "    model.save(f'/content/drive/MyDrive/Colab Notebooks/My Project - SER/text_fold_models/fold_{fold}_model.h5')\r\n",
    "\r\n",
    "    # loss, acc = history.history['loss'][-1], history.history['acc'][-1]\r\n",
    "\r\n",
    "    print(f'Score for fold #{fold}: {model.metrics_names[0]} of {loss}; {model.metrics_names[1]} of {acc * 100}%')\r\n",
    "    acc_per_fold.append(acc * 100)\r\n",
    "    loss_per_fold.append(loss)\r\n",
    "\r\n",
    "    fold += 1 # Increase fold number\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "REvJ5bQcp0cQ",
    "outputId": "b7d8751d-a32c-48f2-e779-ab55bc7d4e00"
   },
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for index, acc in enumerate(acc_per_fold):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {index+1} - Loss: {loss_per_fold[index]} - Accuracy: {acc_per_fold[index]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8c8taWCs6Pgi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "speech_train.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "c5e48f84046969b800ff52f6d80523bcd1ca3fb1a99f1449e4197bf6c73dc096"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}