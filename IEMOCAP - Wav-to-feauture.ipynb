{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Extract Audio Feautures\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\r\n",
    "import pathlib\r\n",
    "import random\r\n",
    "\r\n",
    "import wave\r\n",
    "import python_speech_features as ps\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "from util import *\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import wave\r\n",
    "import python_speech_features as ps"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(\"Version: \", tf.__version__)\r\n",
    "# tf.compat.v1.enable_eager_execution() # Enable eager execution\r\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\r\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices('GPU') else \"NOT AVAILABLE\")\r\n",
    "# print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Version:  1.14.0\n",
      "Eager mode:  False\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUFCiglo5II9",
    "outputId": "5619a59b-f2e1-4987-9b03-1dc55844e141"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## File paths"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "HOME_DIR = pathlib.Path.cwd()\r\n",
    "\r\n",
    "# feature_path = HOME_DIR / 'data' / 'processed'/ 'IEMOCAP' / 'extracted_feature.pk'\r\n",
    "feature_path = 'D:/extracted_features.pk'\r\n",
    "\r\n",
    "label_path = HOME_DIR / 'data' / 'processed' / 'IEMOCAP' / 'FC_label_test.txt'\r\n",
    "processed_id_path = HOME_DIR / 'data' / 'processed' / 'IEMOCAP' / 'processed_ids_test.txt'\r\n",
    "dataset_path = HOME_DIR / 'data' / 'raw'\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def read_file(filename):\r\n",
    "    file = wave.open(filename, 'r')\r\n",
    "    params = file.getparams()\r\n",
    "    nchannels, sampwidth, framerate, wav_length = params[:4]\r\n",
    "    str_data = file.readframes(wav_length)\r\n",
    "    wavedata = np.fromstring(str_data, dtype=np.short)\r\n",
    "    time = np.arange(0, wav_length) * (1.0/framerate)\r\n",
    "    file.close()\r\n",
    "    return wavedata, time, framerate\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def shuffle_dataset(features, labels):\r\n",
    "    # random.seed(24)\r\n",
    "\r\n",
    "    shuffler = np.random.permutation(len(features))\r\n",
    "    return features[shuffler], labels[shuffler]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "list_files = []\r\n",
    "\r\n",
    "for x in range(5, 6):\r\n",
    "    sess_title = 'Session' + str(x)\r\n",
    "\r\n",
    "    path = f'./data/raw/IEMOCAP_full_release/{sess_title}/sentences/wav'\r\n",
    "#     path = dataset_path / 'IEMOCAP_full_release' / f'{sess_title}' / 'sentences' / 'wav'\r\n",
    "\r\n",
    "    file_search(str(path), list_files)\r\n",
    "    list_files = sorted(list_files)\r\n",
    "\r\n",
    "    print(f\"{sess_title}, # Num of files: {len(list_files)}\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Session5, # Num of files: 2170\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get list of filenames in category, (Angry, Happy, Sad, Neutral)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "full_ids = []\r\n",
    "with open(str(processed_id_path)) as f:\r\n",
    "    full_ids = f.readlines()\r\n",
    "full_ids = [x.strip() for x in full_ids]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "full_path = []\r\n",
    "\r\n",
    "for file_ in full_ids:\r\n",
    "    for file2 in list_files:\r\n",
    "        if file_+'.wav' == file2.split('\\\\')[-1]:\r\n",
    "            full_path.append(file2)\r\n",
    "            break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract and save features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def load_data():\r\n",
    "    with open('./zscore40.pkl', 'rb') as f:\r\n",
    "        mean1, std1, mean2, std2, mean3, std3 = pickle.load(f)\r\n",
    "    return mean1, std1, mean2, std2, mean3, std3\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "mean1, std1, mean2, std2, mean3, std3 = load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# dataset_size = 3548 #3548 - consider zero-indexing\r\n",
    "dataset_size = 942  # consider session 5 only(test set)\r\n",
    "filter_num = 40\r\n",
    "eps = 1e-5\r\n",
    "\r\n",
    "dataset = np.zeros((dataset_size, 300, filter_num, 3), dtype=np.float32)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "dataset_size = 0\r\n",
    "for filename in full_path:\r\n",
    "\r\n",
    "    data, time, rate = read_file(filename)\r\n",
    "    mel_spec = ps.logfbank(data, rate, nfilt=40)\r\n",
    "    delta1 = ps.delta(mel_spec, 2)\r\n",
    "    delta2 = ps.delta(delta1, 2)\r\n",
    "\r\n",
    "    time = mel_spec.shape[0]\r\n",
    "\r\n",
    "    if(time <= 300):\r\n",
    "        part = mel_spec\r\n",
    "        delta11 = delta1\r\n",
    "        delta21 = delta2\r\n",
    "\r\n",
    "        part = np.pad(\r\n",
    "            part, ((0, 300 - part.shape[0]), (0, 0)), 'constant', constant_values=0)\r\n",
    "        delta11 = np.pad(\r\n",
    "            delta11, ((0, 300 - delta11.shape[0]), (0, 0)), 'constant', constant_values=0)\r\n",
    "        delta21 = np.pad(\r\n",
    "            delta21, ((0, 300 - delta21.shape[0]), (0, 0)), 'constant', constant_values=0)\r\n",
    "\r\n",
    "        dataset[dataset_size, :, :, 0] = (part - mean1)/(std1+eps)\r\n",
    "        dataset[dataset_size, :, :, 1] = (delta11 - mean2)/(std2+eps)\r\n",
    "        dataset[dataset_size, :, :, 2] = (delta21 - mean3)/(std3+eps)\r\n",
    "\r\n",
    "        dataset_size += 1\r\n",
    "\r\n",
    "    else:\r\n",
    "        for i in range(1):\r\n",
    "            if(i == 0):\r\n",
    "                begin = 0\r\n",
    "                end = begin + 300\r\n",
    "            else:\r\n",
    "                begin = time - 300\r\n",
    "                end = time\r\n",
    "\r\n",
    "            part = mel_spec[begin:end, :]\r\n",
    "            delta11 = delta1[begin:end, :]\r\n",
    "            delta21 = delta2[begin:end, :]\r\n",
    "\r\n",
    "            dataset[dataset_size, :, :, 0] = (part - mean1)/(std1+eps)\r\n",
    "            dataset[dataset_size, :, :, 1] = (delta11 - mean2)/(std2+eps)\r\n",
    "            dataset[dataset_size, :, :, 2] = (delta21 - mean3)/(std3+eps)\r\n",
    "\r\n",
    "            dataset_size += 1\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and prepare features"
   ],
   "metadata": {
    "id": "jA4eEP5wu6nj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Load label data\r\n",
    "label = []\r\n",
    "\r\n",
    "with open(str(label_path)) as f2:\r\n",
    "    category = f2.readlines()\r\n",
    "\r\n",
    "label = [y.strip() for y in category]\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "WwvIqtsJuJVq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Create label Dataframe\r\n",
    "data_dict = {'label': label}\r\n",
    "label_dataset = pd.DataFrame.from_dict(data_dict)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "encoder = OneHotEncoder(sparse=False)\r\n",
    "label_encoded = encoder.fit_transform(label_dataset[['label']])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shuffle features and label"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "features, label = shuffle_dataset(dataset, label_encoded)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Save pre-processed data\r\n",
    "np.save('D:/processed_features3', features)\r\n",
    "np.save('D:/label3', label)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Hold out test-set\r\n",
    "np.save(str(dataset_path) + '/X_test_set55', dataset)\r\n",
    "np.save(str(dataset_path) + '/Y_test_set55', label_encoded)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5e48f84046969b800ff52f6d80523bcd1ca3fb1a99f1449e4197bf6c73dc096"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}